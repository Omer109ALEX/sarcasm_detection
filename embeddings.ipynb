{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_process_data as mpd\n",
    "import create_messages as cm\n",
    "import my_rag as mrag\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import warnings\n",
    "from tabulate import tabulate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings, HuggingFaceEmbeddings, HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, FewShotPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "#model_name = \"llama-3.1-70b-versatile\"\n",
    "#model_name = \"llama-3.1-8b-instant\"\n",
    "model_name = \"llama3-70b-8192\"\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGroq(model=model_name, temperature=0.6 , model_kwargs={\n",
    "    \"top_p\" : 0.7,\n",
    "    \"seed\" : 109,\n",
    "    \"response_format\" : {\"type\": \"json_object\"},\n",
    "    })\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Relevance scores must be between 0 and 1\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"No relevant docs were retrieved using the relevance score threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97254\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\97254\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bitsandbytes\\cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'cadam32bit_grad_fp32' not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\97254\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings\n",
    "#embedding_name = \"sentence-transformers/all-MiniLM-L6-v2\" # SBERT \n",
    "#paraphrase-MiniLM-L12-v2:\n",
    "#all-MiniLM-L12-v2:\n",
    "embedding_name = \"sentence-transformers/all-roberta-large-v1\" # Description: Based on RoBERTa-large, this model has been fine-tuned for various semantic similarity tasks. \n",
    "#embedding_name = \"sentence-transformers/stsb-roberta-large\" # A large model fine-tuned on the STS benchmark, which is great for capturing sentence-level semantics \n",
    "#embedding_name = \"nikesh66/Sarcasm-Detection-using-BERT\" # Sarcasm Detection Model: Detects instances of sarcasm in text, a crucial aspect for understanding nuanced communication.\n",
    "embedding = HuggingFaceEmbeddings(model_name=embedding_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here i checked different embeddings results \n",
    "sentence = \"\"\"\n",
    "what a great day!!!\n",
    "\"\"\"\n",
    "dataset = \"SPIRS\"\n",
    "score_threshold = -100000000.0\n",
    "\n",
    "embedding_name = \"sentence-transformers/all-roberta-large-v1\" # Description: Based on RoBERTa-large, this model has been fine-tuned for various semantic similarity tasks. \n",
    "embedding = HuggingFaceEmbeddings(model_name=embedding_name) \n",
    "print(f\"for embedding : {embedding_name}\\n+++++++++++++++++++++++\\n\")\n",
    "index_path = f\"./faiss/{embedding_name}/{dataset}\"\n",
    "retriever = mrag.get_retriever_similarity_score_threshold(index_path, embedding, score_threshold=score_threshold)\n",
    "print(mrag.ask_llm_with_rag(retriever, llm, sentence, print_prompt=True))\n",
    "\n",
    "embedding_name = \"nikesh66/Sarcasm-Detection-using-BERT\" # Sarcasm Detection Model: Detects instances of sarcasm in text, a crucial aspect for understanding nuanced communication.\n",
    "embedding = HuggingFaceEmbeddings(model_name=embedding_name) \n",
    "print(f\"for embedding : {embedding_name}\\n+++++++++++++++++++++++\\n\")\n",
    "index_path = f\"./faiss/{embedding_name}/{dataset}\"\n",
    "retriever = mrag.get_retriever_similarity_score_threshold(index_path, embedding, score_threshold=score_threshold)\n",
    "print(mrag.ask_llm_with_rag(retriever, llm, sentence, print_prompt=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690\n",
      "2461\n",
      "4594\n",
      "11262\n",
      "21162\n",
      "51479\n",
      "85338\n",
      "153462\n",
      "153462\n"
     ]
    }
   ],
   "source": [
    "# merge faiss\n",
    "to_save_vectorstore = None\n",
    "for dataset in mpd.datasets:\n",
    "    if not to_save_vectorstore:\n",
    "        index_path1 = f\"./faiss/data/{embedding_name}/{dataset}/\"\n",
    "        to_save_vectorstore = FAISS.load_local(index_path1, embeddings=embedding, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        index_path2 = f\"./faiss/data/{embedding_name}/{dataset}/\"\n",
    "        vectorstore2 = FAISS.load_local(index_path2, embeddings=embedding, allow_dangerous_deserialization=True)\n",
    "        to_save_vectorstore.merge_from(vectorstore2)\n",
    "    print(to_save_vectorstore.index.ntotal)\n",
    "\n",
    "\n",
    "print(to_save_vectorstore.index.ntotal)\n",
    "to_save_path = f'./faiss/data/{embedding_name}/all/'\n",
    "to_save_vectorstore.save_local(to_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def remove_text_from_vectorstore(text_to_remove, vectorstore):\n",
    "    print(f\"Initial number of items in vector store: {vectorstore.index.ntotal}\")\n",
    "    \n",
    "    # Retrieve documents with similar text\n",
    "    docs = vectorstore.similarity_search(text_to_remove)\n",
    "    \n",
    "    # Extract the IDs of these documents\n",
    "    ids_to_remove = [doc.metadata[\"id\"] for doc in docs]\n",
    "\n",
    "    # Remove the identified documents from the vector store\n",
    "    vectorstore.delete(ids_to_remove)\n",
    "    \n",
    "    print(f\"Number of items in vector store after deletion: {vectorstore.index.ntotal}\")\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of items in vector store: 153462\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m index_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./faiss/data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mload_local(index_path, embeddings\u001b[38;5;241m=\u001b[39membedding, allow_dangerous_deserialization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m after \u001b[38;5;241m=\u001b[39m \u001b[43mremove_text_from_vectorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mload_local(index_path, embeddings\u001b[38;5;241m=\u001b[39membedding, allow_dangerous_deserialization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter the original is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvectorstore\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mntotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [10], line 10\u001b[0m, in \u001b[0;36mremove_text_from_vectorstore\u001b[1;34m(text_to_remove, vectorstore)\u001b[0m\n\u001b[0;32m      7\u001b[0m docs \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(text_to_remove)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract the IDs of these documents\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m ids_to_remove \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Remove the identified documents from the vector store\u001b[39;00m\n\u001b[0;32m     13\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39mdelete(ids_to_remove)\n",
      "Cell \u001b[1;32mIn [10], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m docs \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(text_to_remove)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract the IDs of these documents\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m ids_to_remove \u001b[38;5;241m=\u001b[39m [\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Remove the identified documents from the vector store\u001b[39;00m\n\u001b[0;32m     13\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39mdelete(ids_to_remove)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "text = \" but its like a real dude ! feel it emoji_3762 emoji_3762\"\n",
    "dataset = \"all\"\n",
    "index_path = f\"./faiss/data/{embedding_name}/{dataset}/\"\n",
    "vectorstore = FAISS.load_local(index_path, embeddings=embedding, allow_dangerous_deserialization=True)\n",
    "after = remove_text_from_vectorstore(text, vectorstore)\n",
    "vectorstore = FAISS.load_local(index_path, embeddings=embedding, allow_dangerous_deserialization=True)\n",
    "print(f'after the original is: {vectorstore.index.ntotal}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Man. I hope @dorkslayer420 liked the drink I made him... =3', 'label': '0', 'dataset': 'SPIRS'}\n"
     ]
    }
   ],
   "source": [
    "file_path = f'./data/random/random_10_filtered.csv'\n",
    "d = mpd.load_csv_as_dict(file_path)\n",
    "print(d[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"all\"\n",
    "score_threshold = 0.0\n",
    "embedding_name = \"sentence-transformers/all-roberta-large-v1\" # Description: Based on RoBERTa-large, this model has been fine-tuned for various semantic similarity tasks. \n",
    "embedding = HuggingFaceEmbeddings(model_name=embedding_name) \n",
    "index_path = f\"./faiss/data/{embedding_name}/{dataset}\"\n",
    "vectorstore = FAISS.load_local(index_path, embeddings=embedding, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before the original is: 153462\n",
      "ids_to_delete: []\n",
      "before the original is: 153462\n"
     ]
    }
   ],
   "source": [
    "print(f'before the original is: {vectorstore.index.ntotal}')\n",
    "\n",
    "dataset = \"all\"\n",
    "\n",
    "sentence = \"\"\"\n",
    "I love that I never have signal at my house! #sarcasm\n",
    "\"\"\"\n",
    "\n",
    "ids_to_delete = []\n",
    "docs = vectorstore.docstore._dict.items()\n",
    "\n",
    "\n",
    "# Iterate through all stored documents\n",
    "for doc_id, doc in docs:\n",
    "    if sentence == str(doc.page_content):  # Adjust this condition to your needs\n",
    "        ids_to_delete.append(doc_id)\n",
    "\n",
    "print(f'ids_to_delete: {ids_to_delete}')\n",
    "# Deleting vectors by IDs\n",
    "for doc_id in ids_to_delete:\n",
    "    vectorstore.index.remove_ids(np.array([doc_id]))\n",
    "\n",
    "# Optionally, remove the documents from the docstore as well\n",
    "for doc_id in ids_to_delete:\n",
    "    del vectorstore.docstore._dict[doc_id]\n",
    "\n",
    "# Save the updated vector store\n",
    "print(f'before the original is: {vectorstore.index.ntotal}')\n",
    "\n",
    "#vectorstore.save_local('./faiss/data/{embedding_name}/{dataset}/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an advanced language model designed to analyze and interpret sentences for sarcasm detection.\n",
      "You must determine whether the sentence below is sarcastic.\n",
      "\n",
      "Base your answer on the provided context, labeled sentences, ordered by most similar at top and so on\n",
      "Ensure that your answer does not contradict or refute any of the provided context sentences.\n",
      "Your answer should be consistent with the information and labels in the context.\n",
      "If there is a sentence in the context that is similar to the given sentence, you should prioritize its label, even if your initial assessment differs.\n",
      "The sentence:\n",
      "\n",
      "Having a really busy day, might only manage the one box set today\n",
      "\n",
      "\n",
      "Context:\n",
      "\n",
      "{'sentence': 'Having a really busy day, might only manage the one box set today', 'prediction': '1', 'dataset': 'SemEval2022'}\n",
      "{'sentence': 'Nothing to do today, might watch a box set', 'prediction': '0', 'dataset': 'iSarcasmEval'}\n",
      "{'sentence': 'super crazy busy day at work today', 'prediction': '1', 'dataset': 'multimodal_sarcasm_detection'}\n",
      "\n",
      "The output should be formatted as the JSON schema:\n",
      " {\"prediction\": \"1\" if sarcastic or \"0\" if not}, do not add any more tokens\n",
      "\n",
      "\n",
      "({'prediction': '1'}, [Document(metadata={'source': './data/SemEval2022/data.csv', 'row': 1961, 'label': '1', 'dataset': 'SemEval2022'}, page_content='Having a really busy day, might only manage the one box set today'), Document(metadata={'source': './data/iSarcasmEval/data.csv', 'row': 4818, 'label': '1', 'dataset': 'iSarcasmEval'}, page_content='Having a really busy day, might only manage the one box set today'), Document(metadata={'source': './data/iSarcasmEval/data.csv', 'row': 4978, 'label': '1', 'dataset': 'iSarcasmEval'}, page_content='Having a really busy day, might only manage the one box set today'), Document(metadata={'source': './data/iSarcasmEval/data.csv', 'row': 4553, 'label': '0', 'dataset': 'iSarcasmEval'}, page_content='Nothing to do today, might watch a box set'), Document(metadata={'source': './data/iSarcasmEval/data.csv', 'row': 6079, 'label': '0', 'dataset': 'iSarcasmEval'}, page_content='Nothing to do today, might watch a box set'), Document(metadata={'source': './data/multimodal_sarcasm_detection/data.csv', 'row': 15957, 'label': '1', 'dataset': 'multimodal_sarcasm_detection'}, page_content='super crazy busy day at work today'), Document(metadata={'source': './data/Ptacek/data.csv', 'row': 54475, 'label': '0', 'dataset': 'Ptacek'}, page_content='4 pages down 5 more to go ð\\x9f\\x98\\x85... Iâ\\x80\\x99ll finish them tomorrow'), Document(metadata={'source': './data/Ptacek/data.csv', 'row': 25068, 'label': '1', 'dataset': 'Ptacek'}, page_content='Planning out the schedule for the rest of my day &amp; its looking pretty busy #sarcasm'), Document(metadata={'source': './data/Ptacek/data.csv', 'row': 28009, 'label': '1', 'dataset': 'Ptacek'}, page_content='So busy. Busy busy bee at work. I wish I had less to do #sarcasm'), Document(metadata={'source': './data/Ptacek/data.csv', 'row': 37422, 'label': '0', 'dataset': 'Ptacek'}, page_content='May or may not have gone absolutely feral at the oxfam and bought 7 star trek box sets')])\n"
     ]
    }
   ],
   "source": [
    "# Here i checked filter function\n",
    "sentence = \"\"\"\n",
    "Having a really busy day, might only manage the one box set today\n",
    "\"\"\"\n",
    "dataset = \"all\"\n",
    "score_threshold = 0.0\n",
    "index_path = f\"./faiss/data/{embedding_name}/{dataset}\"\n",
    "\n",
    "retriever = mrag.get_retriever_similarity_score_threshold(index_path, embedding, score_threshold=score_threshold, k=10)\n",
    "print(mrag.ask_llm_with_rag(retriever, llm, sentence, \"iSarcasmEval\", print_prompt=True, with_dataset=True))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
